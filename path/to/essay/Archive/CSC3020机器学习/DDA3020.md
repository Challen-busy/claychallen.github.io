[TOC]

------

# lec1：intro

#### Artificial Branch

![image-20240111193723808](C:\Users\chall\AppData\Roaming\Typora\typora-user-images\image-20240111193723808.png)

**Supervised learning**: you are also provided some **human-labeled** outputs  y1*,* y2*,* y3*, . . .*, and your task is to learn a mapping function from one inputdata x*i* to one output y*i* . Learning from teacher

**Unsupervised learning**: your task is to build/learn a good model of x, such that some characteristics of the data could be revealed, such as clustering, dimensionality reduction, *etc.* Learning by oneself

**Reinforcement learning**:您可以采取一些行动； 改变data c； （环境状态），您将获得一些奖励/惩罚； 逐渐地，您将自动学习制作合适的动作福特数据以获得更多的奖励。 这是三个基本的机器学习范式之一,与监督的学习和无监督的学习学习并列。



#### Supervised learning

​	`regression and classification

<img src="https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240111220026042.png" alt="image-20240111220026042" style="zoom:80%;" />

1. **目标函数（Target Function）**：
   - 目标函数是我们想要找到的“理想”函数，它完美地描述了输入（X）和输出（Y）之间的关系。在现实中，我们通常不知道这个函数是什么，但我们的目标是尽可能接近它。
2. **假设（Hypothesis）**：
   - 假设是我们根据数据建立的一个函数，它是目标函数的一个近似。我们通过调整这个假设，尝试使它更接近目标函数。例如，如果我们的数据是关于房屋面积和价格的，一个假设可能是价格等于面积乘以某个系数。
3. **假设空间（Hypothesis Space）**：
   - 假设空间是所有可能的假设的集合。换句话说，它定义了我们可以考虑的所有不同类型的函数形式。在监督学习中，我们的目标是在这个空间中找到最佳的假设。
4. **成本函数（Cost Function）**：
   - 成本函数用于评估假设的效果。它衡量假设预测的输出和真实输出之间的差距。成本函数越低，意味着我们的假设越接近目标函数。
5. **目标函数（Objective Function）**：
   - 在机器学习中，目标函数是我们希望优化（最小化或最大化）的函数。在许多情况下，目标函数就是成本函数，我们的目标是通过调整假设来最小化这个成本。
6. **训练/学习（Training/Learning）**：
   - 训练或学习是通过优化目标函数来找到最佳假设的过程。这通常是通过在一组训练数据上进行的，其中我们调整假设，以最小化它们预测的输出和实际输出之间的差异。
7. **测试/评估（Testing/Evaluation）**：
   - 测试或评估是在一个独立的测试数据集上检验学习到的模型的过程。这是为了确保我们的模型不仅在训练数据上表现良好，而且能够对新的、未见过的数据做出准确的预测。

#### Unsupervised learning

​	`clustering and dimensionality reduction

<img src="https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240111220548993.png" alt="image-20240111220548993" style="zoom:80%;" />





#### Regression vs. Classification

Regression with continuous output vs. Classification with finite and discrete or categorical outputs

#### Dimensionality reduction and clustering

------

# lec2: Information theory

#### Statistic Basic

#####  Probability, event, random variables, Sample space,Random experiment

​	***X* : S → R:**x是函数——将sample space（正反面）映射到real space（0，1）    （这个X有别于变量X，长得其实不一样）

​	**Event :**Disjoint event/Overlapping Event(独立/重合事件)

- 全排列：n！
- Overlapping sort：A
- Overlapping select: C
- All Disjoint: E(A)\*E(B)为事件数量

​	**Bayes**:Joint, marginal, conditional probability

- union probability: *P*(*A* *∪* *B*) = P(*A*) + *P*(*B*) *−* *P*(*A* *∩* *B*)非独立*,*|= ***P*(*A*) + *P*(*B*)**–独立

- Joint probabilities：***P*(*A, B*)** = *P*(*A* *∩* *B*) = *P*(*A**|**B*)*P*(*B*) = *P*(*B**|**A*)*P*(*A*)

- Marginal distribution: sum rule，A的(概率)等于AB联合概率中B所有情况。
  $$
  P(A)=\sum_{b}{P(A,B)}=\sum_{b}{P(A|B=b)P(B=b)}
  $$

- Conditional probability(same Joint probabilities): 
  $$
  P(A|B)={\frac{P(A\cap B)}{P(B)}}
  $$

- **Bayes：贝叶斯法则允许我们从已知的条件概率分布 P(B | A) 推导出我们感兴趣的条件概率分布 P(A | B)，**

  ![4174bdd5979b6349da0511c32f565c4](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Picture4174bdd5979b6349da0511c32f565c4.jpg)

  

  ##### 其他概念：

  Independent:P(X)=P(X|Y)
  $$
  X\,\perp Y\Longleftrightarrow P(X,Y)=P(X)P(Y).
  $$

  1. 期望（均值）： 
     $$
     E(x)=\sum_{x\in X}x\cdot P(X=\alpha)
     $$

  2. 函数的期望： 
     $$
     {\cal E}(f(X))=\sum_{x c-X}f(x)\cdot{\cal P}(x\to\alpha)
     $$

  3. 矩（Moments）：随机变量 X 的幂的期望。 
     $$
     M_{k}\,=\,E(X^{k})
     $$

  4. 方差（Variance）：随机变量 X 偏离均值的平均平方差异。 
     $$
     V a r(X)=E((X-E(X))^{2})=E(X^{2})-(E(X))^{2}
     $$

  5. 标准差（Standard Deviation）：方差的平方根。 
     $$
     S t d={\sqrt{V a r(X)}}
     $$

 

##### Continuous random variables的表示方法

![image-20240120055442316](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240120055442316.png)

![image-20240120055453381](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240120055453381.png)

#####  Some common discrete distributions

二项分布：
$$
\operatorname{Bin}(m|N,\mu)={\binom{N}{m}}\mu^{m}(1-\mu)^{N-m}
$$

$$
{\binom{N}{m}}={\frac{N!}{(N-m)!m!}}
$$

$$
N实验，m成功次数， µ成功概率
$$

$$
\begin{array}{l}{{\mathbb{E}[m]=\sum_{m=0}^{N}m\mathrm{Bin}(m|N,\mu)=N\mu}}\\ {{\operatorname{var}[m]=\mathbb{E}[(m-N\mu)^{2}]=N\mu(1-\mu)}}\end{array}
$$



Bernoulli distribution：
$$
单次二项实验，就是伯努利分布
$$


##### Some common continuous distributions

Gaussian distribution：***µ*** is the **mean** and **σ^2^** is the **variance**
$$
{\mathcal{N}}(x|\mu,\sigma)={\frac{1}{(2\pi\sigma^{2})^{\frac{1}{2}}}}\exp\left(-{\frac{(x-\mu)^{2}}{2\sigma^{2}}}\right)
$$
multivariate Gaussian:(extra)

> **µ** is a *D*-dimensional **mean vector**, and **Σ** is a *D* *×* *D* **covariance**
>
> **matrix**, and *|***Σ***|* denotes the determinant of **Σ**.
> $$
> N(x|\mu,\Sigma)={\frac{1}{(2\pi)^{\frac{d}{2}}|\Sigma|^{\frac{1}{2}}}}\exp\left(-{\frac{(x-\mu)^{\top}\Sigma^{-1}(x-\mu)}{2}}\right)
> $$

 

#### Information theory

##### Information:

“信息”是不确定性的度量衡，这是x事件的可能性：
$$
{\mathcal{X}}=\{x_{0},\cdot\cdot\cdot,x_{k},\cdot\cdot\cdot x_{S}\},
$$

$$
P(X=x_{k})=p_{k}
$$

而可能性意味着不确定性，信息获取的对象称为“源”；

单位为bit，信息量被定义为：
$$
I(x_{k})=\log{\frac{1}{p_{k}}}=-\log(p_{k})
$$


当其real space事件为1件，那他就是确定的，比如1=1；

![image-20240120093733678](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240120093733678.png)


$$
{\cal I}(p)=-\log_{2}(p)曲线图：
$$
![image-20240120093929796](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_PictureTypora_Pictureimage-20240120093929796.png)

在这个图中，概率 *p* 的值从 0.01 到 1 变化。您可以看到，当事件发生的概率 p接近 0（即事件非常罕见）时，从该事件中获得的信息量是最高的。相反，当事件几乎肯定会发生（概率接近 1）时，从该事件中获得的信息量较低。**这反映了信息论的基本原则：更不确定的事件提供了更多的信息。**



##### Entropy：

熵是从“源”获取信息量的期望：
$$
\begin{array}{c}{{\mathrm{\Large~}}}\\ {{{\cal H}_{P}(\not{X}^{\prime})=E[I(x_{k})]}}\\ {{\mathrm{}=-\sum_{x_{k}\in\chi}p_{k}\cdot I(x_{k})}}\end{array}
$$
比如样本空间S={0，1}，那么
$$
\begin{array}{l}{{H_{P}(\chi^{\prime})=E[I(x_{k})]}}\\ {{=-p_{0}\log p_{0}-p_{1}\log p_{1}}}\\ {{=-p_{0}\log p_{0}-(1-p_{0})\log\left(1-p_{0}\right)}}\end{array}
$$


###### Cross Entropy：

交叉熵是信息论中的一个重要概念，经常用在机器学习和深度学习中，尤其是在分类问题的损失函数中。它衡量的是当使用一个**错误的概率分布**来编码来自另一个**真实分布的事件**时，所需要的**额外的信息量**。
$$
P(x) 是观察到的真实数据中事件 x 的概率，而Q(x) 是模型预测事件 x 发生的概率：
$$

$$
H_{P,Q}(X)=-\sum_{x_{k}\in{\mathcal{X}}}P(X=x_{k})\cdot\log(Q(X=x_{k}))
$$

$$
H_{P.Q}(X)\;\ge\;H_{P}(X),
$$

###### Relative entropy: Kullback-Leibler divergence：

KL散度是衡量两个概率分布差异的度量。它衡量的是如果我们假设数据是由分布 Q生成的，而实际上是由分布 P 生成的，那么我们**期望损失多少信息**。简单来说，KL散度衡量了使用概率分布 Q 来近似概率分布 P 时的信息损失。





##### 总结：

- **交叉熵**通常用于衡量模型预测分布与真实分布之间的差异，是机器学习中常用的损失函数之一。
- **KL散度**用于衡量两个概率分布之间的差异，它是衡量分布相似性的一个非常有用的工具。

------

# lec3: Linear Algebra

### Notations, vectors, matrices

> scalar标量
>
> summation 和, 合计
> $$
> \sum_{i=1}^{m}x_{i}=x_{1}+x_{2}+\dots+x_{m}
> $$
> product：积
> $$
> \prod_{i=1}^{m}x_{i}=x_{1}\cdot x_{2}\cdot\ldots\cdot x_{m}
> $$
> A **vector** ：
>
> ​	is an ordered list of scalar values, called attributes.(bold character denoted)
>
> 
>
> A **matrix**:
> $$
> \mathbf{X}=\left[21\quad u\quad-3\right]
> $$
> **Matrix-Vector Product**
>
> ![image-20240120201543389](C:\Users\chall\AppData\Roaming\Typora\typora-user-images\image-20240120201543389.png)
>
> 



### Matrix inverse, determinant, independence

**Matrix inverse： AB** = **BA** = **I** (Identity matrix)

**Determinant(模) computation：**

如果det(A)=0,那么A是dependent的，道心有缺
$$
\operatorname{det}(\mathbf{A})=|\mathbf{A}|={\left|\begin{array}{l l}{a}&{b}\\ {c}&{d}\end{array}\right|}=a d-b c
$$
linearly dependent:
$$
\beta_{1}\mathbf{x}_{1}+\dots+\beta_{m}\mathbf{x}_{m}=0可以有所表示
$$
linearly independent：
$$
\beta_{1}\mathbf{x}_{1}+\dots+\beta_{m}\mathbf{x}_{m}=0只存在于所有向量都为zero
$$

### Systems of linear equations

##### 如何判断linear equation有（1/n/0）种解

1. 行列式值

   **invertible = unsingular matrix = {det(A)≠0}：**

   ​	可逆矩阵 = 非奇异矩阵=行列式值不为零=也无相关/线性重复向量=唯一解！因为相关向量会让矩阵不满秩，因而相乘不可能等于单位矩阵。咱也可以用行列式判断是否存在解。

   - det(A) ≠ 0：唯一解
   - det(A) = 0 且行阶梯形式中不存在自由变量：无解
   - det(A) = 0 且行阶梯形式中存在自由变量：无穷多解

2. 增广矩阵、系数矩阵、未知数个数比较：

   - 增广矩阵的秩 = 系数矩阵的秩 = 未知数个数，则有唯一解。
   - 增广矩阵的秩 = 系数矩阵的秩 ＜ 未知数个数， 则有无穷解。
   - 增广矩阵的秩 ≠ 系数矩阵的秩，无解！

3. 观察最简行阶梯

   - 如果未知数等于式子数量，唯一解
   - 如果未知数大于式子数量，无穷解
   - 如果未知数小于有效式子数量，无解

------

# lec4: Linear Regression

### Function  映射/方程  、gradient 梯度

domain(域) vs. Codomain(值域)

Scalar function标量方程 vs. Vector function.向量方程

##### 线性映射：

![image-20240305200434023](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240305200434023.png)

仿射函数：是线性函数的平移，f(x)=a^T^ + b，那么b就叫offset-偏移量。

##### 线性映射性质：

- **Homogeneity** ；**Additivity**缩放、加减函数都等同于操作函数值，这是线性方程、线性映射的规律。

- **superposition**：叠加性
  ![image-20240305201445855](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240305201445855.png)

  



**interval区间** vs **open interval开区间** 

**local minima局部变量** vs **global minima全局变量**

**arg max f(a)返回最大值处的元素** vs **max f(a)返回最大值**: 

**derivative f ’导数** vs **slope斜率**

##### **Partial Derivative偏导数**

偏导数是多元函数在某一点沿着某个坐标轴方向的导数。在一元函数中，导数表示函数在某一点的变化率；而在多元函数中，偏导数则表示函数在某一点沿着某个坐标轴方向的变化率。

举个通俗的比喻来说，假设你站在一个山坡上，想知道沿着哪个方向下山的速度最快。这时候，山坡就可以看作是一个多元函数，你所站的位置就是函数的某个点，而偏导数就是告诉你沿着哪个方向下山的速度最快。

![image-20240305202928217](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240305202928217.png)

如果 f(w) 是一个关于向量 w 的函数，那么它的偏导数就是告诉你在 w 点沿着每个坐标轴方向的下降率（或者上升率）。

举个简单的例子，假设 f(w) = w1^2 + w2^2，w 是一个二维向量 (w1, w2)。那么 f(w) 的偏导数就是 (∂f/∂w1, ∂f/∂w2) = (2w1, 2w2)。这意味着在点 w 处，沿着 w1 轴方向的下降率是 2w1，沿着 w2 轴方向的下降率是 2w2。

##### 一些小公式：

![image-20240305203556441](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240305203556441.png)

![image-20240308000714884](C:\Users\chall\AppData\Roaming\Typora\typora-user-images\image-20240308000714884.png)







![image-20240307235425252](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240307235425252.png)







在中文中，"eigenvalue" 翻译为 "特征值"，而 "orthogonal matrix" 翻译为 "正交矩阵"。

- **特征值：在线性代数中，给定一个方阵 A*，如果存在一个非零向量 *v* 和一个标量 *λ* 使得 =*Av*=*λv*，那么我们称 *λ* 是矩阵 *A* 的一个特征值，而 v* 称为对应于 *λ* 的特征向量。**
- **正交矩阵：是指一个方阵  *Q*，满足 ==*Q^T^Q*=*QQ^T^*=*I* 的性质，其中 *Q^T^* 表示 *Q* 的转置，*I* 表示单位矩阵。正交矩阵的列向量组成了一个标准正交基。**



凸集Convex证明定义法：

![image-20240307225432162](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240307225432162.png)

1. **二阶导数检验（对于一元函数）：** 如果函数 �:�→�*f*:R→R 可以求得二阶导数，那么它是凸函数当且仅当它的二阶导数在任何地方都非负，即 �′′(�)≥0*f*′′(*x*)≥0 对所有 �∈�*x*∈R 都成立。
2. **Hessian 矩阵（对于多元函数）：** 如果函数 �:��→�*f*:R*n*→R 可以求得二阶导数，那么它是凸函数当且仅当它的 Hessian 矩阵在每一点都是正半定的，即 ∇2�(�)⪰0∇2*f*(*x*)⪰0 对所有 �∈��*x*∈R*n* 都成立。

------

### Linear Regression线性回归预测

#### Methodology

##### **Linear hypothesis function:**线性假设方程

$$
f_{\mathrm{w.b}}(\mathbf{x})=\mathbf{x}^{\mathsf{T}}\mathbf{w}+b,
$$

其中e称为观察噪声observation noise 或残留误差residual error、bias term，并且是独立于使用任何特定的输入x。
$$
y={\bf w}^{\textsf{T}}{\bf x}+e,\mathrm{~where~}e\sim N(0,\sigma^{2})
$$


##### loss function:损失函数

损失函数是对  错误分类的惩罚量度，这是其中一种，称为squared error loss.平方误差损失
$$
\frac{1}{m}\sum_{i=1}^{m}\left(f_{\mathrm{w},b}\,(\mathbf{x}_{i})-y_{i}\right)^{2}
$$
所有基于模型的学习算法都有损失函数。我们的工作是最大程度地减少成本函数cost function。
 在linear regression线性回归中，成本函数cost function由平均损失average function给出,称为经验风险empirical risk。

##### MLE：最大似然估计


最大似然估计（MLE, Maximum Likelihood Estimation）是一种在给定观测数据的情况下，估计模型参数的方法。它的核心思想是找到一组参数，使得在这组参数下，观测到当前数据的概率（似然）最大。

**步骤**：

1. **定义似然函数**：对于给定的数据集和模型，首先定义似然函数。似然函数是参数的函数，表示在给定参数下观测到当前数据的概率。对于不同的问题，似然函数的形式会有所不同。
2. **对数化**：为了简化计算，通常对似然函数取对数，得到对数似然函数。
3. **求导**：对对数似然函数关于参数求导，得到导数表达式。
4. **求最大值**：求解导数等于零的参数值，这些值使得对数似然函数达到最大，即为最大似然估计值。

![image-20240305214350703](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240305214350703.png)

#### Using

notation：

> ![image-20240305215530453](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240305215530453.png)

##### 正规方程求解 w、b（最小二乘回归）

所有线性模型都可以假设成：
$$
f_{\mathrm{w.b}}(\mathbf{x})=\mathbf{x}^{\mathsf{T}}\mathbf{w}+b,
$$
其中b为偏置项，w是参数向量。我们要训练求出的是合适的参数 w 和 b ，我们要预测的是以后的input x向量和y向量的关系。那么我们应该假设平方误差损失函数为 J(w)：

![image-20240305221415428](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240305221415428.png)

我们要将它降到最小，所以对它求w偏导数假设为0：

![image-20240305221439058](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240305221439058.png)

- 化简之后得到w公式（无偏置项）：

$$
{\hat{\mathbf{w}}}=\left(\mathbf{X}^{\mathsf{T}}\mathbf{X}\right)^{-1}\mathbf{X}^{\mathsf{T}}\mathbf{y}
$$

- 那么以后的预测就是带入新的X~new~即可：
  $$
  f_{\mathrm{w},b}\left(\mathbf{X}_{\mathrm{new}}^{\,\cdot\,}\right)=\mathbf{X}_{\mathrm{new}}\,\hat{\mathbf{w}}
  $$

（需要点求逆矩阵的技术，还有矩阵乘法技术，很简单的）

##### 梯度下降法



### Training

我们来通过一个简单的二元分类问题来演示如何使用线性回归进行分类。假设我们有以下数据集，包含两个特征（x1, x2）和一个二元标签（y）：

![image-20240307214100179](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240307214100179.png)

我们的目标是构建一个线性回归模型来预测 y 的值，然后根据预测值的正负来分类。

1. ##### 数据准备

我们已经有了特征 (x1, x2) 和标签 y。对于二元分类问题，我们将标签编码为 -1 和 +1，所以不需要额外的处理。

2. ##### 模型构建

我们构建一个线性回归模型：

*y*=*w*1×x~1~+w~2~×x~2~+b

其中 w~1~ 和 w~2~ 是模型的权重，b是偏置项。

3. ##### 训练模型

为了简化问题，我们这里手动选择权重和偏置项，而不是通过优化算法来学习它们。假设我们选择的权重和偏置项为：

*w*1=1,*w*2=−1,*b*=0

则模型为：

*y*=1×*x*1−1×*x*2+0

用这个模型对训练数据进行预测：

![image-20240307214359708](https://raw.githubusercontent.com/Challen-busy/Typora_Picture/main/Typora_Pictureimage-20240307214359708.png)

其中，y_pred 是模型的预测值，y_pred_class 是根据 y_pred 的正负来判断的分类结果。

4. ##### 预测和分类

对于一个新的样本，比如 (x1, x2) = (3, 2)，我们可以使用模型来进行预测：

y~new~=1×3−1×2+0=1

因为预测值为正，所以我们将这个样本分类为 +1 类别。

5. ##### 评估模型

在这个简单的例子中，我们可以看到模型在训练数据上的准确率为 50%（2/4）。当然，在实际应用中，我们会使用更复杂的数据集和优化算法来训练模型，并使用更多的评估指标来评估模型的性能。


$$
\operatorname*{min}_{\mathbf{w},b}\sum_{i=1}^{N}(f_{\mathbf{w},b}(\mathbf{x}_{i})-y_{i})^{2}+\lambda\mathbf{\bar{w}}^{T}\bar{\mathbf{w}},
$$

------



Multi-class Classification

### 一对所有（One-vs-All）策略

这种策略是对每个类别训练一个二元逻辑回归分类器，其中这个类别的样本为正类，其他所有类别的样本为负类。比如，如果我们有三个类别：猫、狗和兔子，我们就训练三个分类器：

- 第一个分类器训练识别猫和非猫；
- 第二个分类器训练识别狗和非狗；
- 第三个分类器训练识别兔子和非兔子。

对于一个新的样本，我们运行所有这三个分类器，然后选择输出最高分（即最有可能的类别）的分类器对应的类别作为预测结果。

**优点**：实现简单。 **缺点**：训练成本高，随着类别数量的增加，模型的规模和训练时间也线性增加，不易扩展到类别很多的任务。

### Softmax回归

Softmax回归是一种直接将逻辑回归推广到多类别的方法，不需要训练多个二分类器。在Softmax回归中，每个类别都有自己的权重向量和偏置项，模型会计算样本属于每个类别的概率，这些概率和为1。

Softmax函数定义了如何根据输入计算每个类别的概率，而成本函数（Cost function）衡量的是模型预测的概率分布与真实标签之间的差异。

在训练过程中，我们使用梯度下降（Gradient Descent）来更新权重，以最小化成本函数。梯度下降的每一步都需要计算成本函数关于每个权重的偏导数，然后根据这个偏导数来更新每个权重。

**优点**：直接针对多类别问题设计，不需要像一对所有那样训练多个模型。 **缺点**：实现和优化相对复杂，特别是当类别非常多时，计算成本较高。











### 你需要学习什么

1. **逻辑回归和Sigmoid函数**：理解这些基本概念以及它们在分类任务中的应用。
2. **过拟合及其解决方案**：学习什么是过拟合，以及如何通过正则化和引入先验知识来减轻过拟合。
3. **概率和统计**：掌握条件概率、对数似然等基础概率统计知识，为理解和实施模型提供理论基础。
4. **梯度上升/下降优化方法**：了解如何使用这些方法来优化你的模型参数，包括如何计算梯度以及如何根据这些梯度更新模型参数。
5. **多类别分类策略**：了解如何从二分类扩展到多类别分类，特别是softmax回归的应用。







Sigmoid函数是一种广泛用于机器学习和深度学习中的非线性激活函数。它的数学表达式为：
$$
\sigma(x)={\frac{{1}}{{1}{+}{e^{-x}}}}
$$


### Sigmoid函数的特性

1. **输出范围**：Sigmoid函数的输出范围在(0, 1)之间，这使得它特别适合用来做二分类问题中的概率预测。例如，在逻辑回归模型中，Sigmoid函数可以将线性回归模型的输出转换成一个概率值，表示某个样本属于正类的概率。
2. **形状**：Sigmoid函数形状为S型曲线（因此得名）。当输入�*x*接近正无穷时，输出接近1；当输入�*x*接近负无穷时，输出接近0；当输入�=0*x*=0时，输出恰好为0.5。
3. **梯度**：Sigmoid函数的梯度随着输入�*x*的绝对值增加而减小，这意味着当�*x*的绝对值很大时，Sigmoid函数的梯度接近于0，这可能导致在使用梯度下降算法进行参数更新时出现梯度消失问题。

### Sigmoid函数的用途

1. **二分类问题**：在逻辑回归中，Sigmoid函数将特征的线性组合转换成概率，用于预测样本属于某一类的概率。
2. **概率输出**：由于Sigmoid函数的输出范围是(0, 1)，它可以被解释为概率值，非常适合表示二元事件发生的概率。
3. **神经网络激活**：在神经网络的早期发展阶段，Sigmoid函数被广泛用作激活函数，用于添加网络的非线性特性，尽管现在在深层网络中更倾向于使用ReLU及其变体以避免梯度消失问题。

### 我们为什么要求Sigmoid函数

在机器学习问题中，特别是在处理逻辑回归时，我们通常关注Sigmoid函数的以下几个方面：

1. **函数形状**：了解Sigmoid函数如何随输入变化，特别是它是如何将任意实数映射到(0, 1)区间的，这对于理解模型的预测行为至关重要。
2. **梯度**：在优化过程中，我们需要计算损失函数关于参数的梯度。由于Sigmoid函数在逻辑回归中用于计算概率，它的梯度对于参数的更新至关重要。
3. **过拟合与权重**：探讨Sigmoid函数在逻辑回归中如何受到大权重影响，以及这种影响如何导致过拟合，是理解和应用逻辑回归模型时的一个重要方面。



### 激活函数

想象你在管理一个大型公司，而神经网络中的每个神经元就像是公司中的一位员工。这位员工（神经元）的工作（激活函数）是根据收到的信息（输入数据）做出决定，并将结果传递给下一位员工（下一个神经元）。但这位员工并不是简单地把收到的信息原封不动地转发出去；而是根据自己的“经验”（激活函数）来“加工”这些信息。如果没有“经验”（即没有激活函数），那么无论这位员工多聪明，他/她只能机械地转发信息，而不能加以创造性地处理。因此，激活函数的作用就像是给员工提供了处理信息的能力，使得整个公司（神经网络）能够完成复杂的任务，如创新和解决问题。

- **作用**：激活函数在神经网络的每一层中用于引入非线性，使得网络可以学习复杂的模式。不同的激活函数有不同的数学特性，比如Sigmoid函数能够将输出压缩到0和1之间，ReLU（Rectified Linear Unit）函数则能够增加网络的稀疏性和计算效率。
- **位置**：应用于神经网络中每个神经元的输出上。

### 损失函数

- **作用**：损失函数（或成本函数）用来衡量模型的预测输出与真实标签之间的差异。它是模型训练过程中需要最小化的目标，因此直接关系到模型的性能。
- **位置**：在整个网络的输出层之后，用于评估模型的整体表现。

**配合**：激活函数的选择会影响模型的学习能力和收敛速度，而损失函数的选择则影响模型优化的方向和速度。在训练过程中，基于损失函数计算得到的梯度用于更新网络中的权重，这一过程会考虑通过激活函数得到的输出。



## 如何机器学习

### 1. 数据探索与预处理

- **理解数据**：首先，通过可视化和统计分析了解你的数据集。这包括检查数据维度、特征类型（数值型、类别型）、缺失值、数据分布等。

  - ### 归一化 (Min-Max Normalization):

    归一化会将所有特征值缩放到 [0,1][0,1] 的范围内。计算公式为：
    $$
    {\frac{x-\operatorname*{min}(x)}{\operatorname*{max}(x)-\operatorname*{min}(x)}}\,,
    $$

  - 标准化会将数据的平均值调整为0，标准差调整为1。计算公式为：
    $$
    \frac{x-\mu}{\sigma}
    $$
    

- **数据清洗**：处理缺失值、异常值、错误数据。这可能意味着填充缺失值、删除或更正错误的数据点。

  - 比如缺失值用中位数、平均数或者最高出现频率值代替。
  - 设置maxvalue，确保数据是正常的。

- **特征工程**：基于对数据的理解，生成新的特征或修改现有特征，以提高模型的性能。这可能包括特征选择、特征提取、编码类别特征（如独热编码）、归一化或标准化数值特征等。

### 2. 选择目标变量与模型类型

- **定义问题**：明确你的机器学习问题是分类、回归还是聚类。比如，如果你是基于`weather.csv`预测天气状况（晴、雨等），这是一个分类问题。
- **选择模型**：根据问题类型和数据特性选择合适的模型。对于初步尝试，可以从简单模型（如线性回归、逻辑回归）开始，然后尝试更复杂的模型（如随机森林、支持向量机、神经网络）。

### 3. 划分数据集

- **训练/测试分割**：通常将数据分为训练集和测试集，有时还会划分出验证集或使用交叉验证来调参和评估模型。

### 4. 模型训练与参数调优

- **选择损失函数和优化算法**：根据模型类型和任务目标选择适当的损失函数和优化算法。

  - 正则化：

    Machine Learning在机器学习中，常用的正则化方法有L1正则化、L2正则化，以及它们的组合（Elastic Net正则化）。下面是这些正则化方法和它们适用的场景，以及与原损失函数结合的完整公式：

    ### 1. L1 正则化（Lasso正则化）

    **公式**：![image-20240322163128031](C:\Users\chall\AppData\Roaming\Typora\typora-user-images\image-20240322163128031.png)

    其中*J*(*w*) 是未加正则化的原始损失函数，*λ* 是正则化强度参数，*w~j~* 是模型的权重。

    **适用场景**：当你需要进行特征选择，或者当你的数据集中包含很多不相关的特征时，L1正则化非常有用。它倾向于产生稀疏的权重矩阵，即很多权重会变成零。这样，一些不重要的特征对模型的贡献会被自动削减掉。

    ### 2. L2 正则化（岭回归/权重衰减）

    **公式**： ![image-20240322163215909](C:\Users\chall\AppData\Roaming\Typora\typora-user-images\image-20240322163215909.png)

    与L1正则化类似，其中*J*(*w*) 是未加正则化的原始损失函数，*λ* 是正则化强度参数，*w~j~* 是模型的权重。

    **适用场景**：适用于大多数学习任务，尤其是当你担心模型过拟合时。L2正则化可以有效地控制模型的复杂度，确保权重不会变得过大，从而避免过拟合。不同于L1正则化，L2正则化不会使权重变为零，而是使它们接近零。

    ### 3. Elastic Net 正则化

    **公式**：![image-20240322163231964](C:\Users\chall\AppData\Roaming\Typora\typora-user-images\image-20240322163231964.png)

    这里 *λ*1 和 *λ*2 分别是L1和L2正则化的强度参数。

    **适用场景**：当你的数据集中既包含很多相关特征，又包含很多不相关特征时，Elastic Net正则化提供了一种中间的解决方案。它结合了L1正则化的特征选择能力和L2正则化防止模型过拟合的能力。Elastic Net特别适合处理特征数多于样本数的情况。

    每种正则化方法都有其特定的应用场景。选择哪种正则化方法，以及设置多大的正则化强度，通常需要基于交叉验证等方法来决定，以达到最佳的模型性能。

- **参数调优**：使用验证集或交叉验证来调整模型参数（如学习率、正则化项）。这可能涉及到使用网格搜索或随机搜索等方法。

### 5. 模型评估

- **选择评估指标**：根据问题类型（分类、回归、聚类）选择合适的评估指标，如准确率、召回率、F1分数、均方误差等。
- **评估模型性能**：使用测试集评估模型的泛化能力。

### 6. 模型优化与部署

- **模型优化**：基于测试结果，可能需要返回进行更多的特征工程、调整模型参数或尝试不同的模型。
- **模型部署**：一旦满意，模型就可以被部署到生产环境中。







### 线性回归和逻辑回归

- **线性回归**：想象你在做柠檬水摊，你记录下每天的气温和你卖出的柠檬水数量。线性回归就是找出气温和柠檬水销量之间的直线关系，以预测在特定气温下你能卖出多少柠檬水。
- **逻辑回归**：如果你要预测明天是否会下雨，以决定是否在户外摆摊。你记录下了以往的天气状况和是否下雨的数据，逻辑回归帮助你根据明天的天气情况来估算下雨的概率。虽然叫做回归，但逻辑回归实际上是用于分类问题的，特别是二分类问题。



### 评估指标的选择

- 对于不同类型的机器学习问题，确实有一套公认的评估指标。例如：
  - **分类问题**：准确率、召回率、F1分数等。
  - **回归问题**：均方误差（MSE）、均方根误差（RMSE）、平均绝对误差（MAE）等。
- 这些指标都有对应的数学公式，不需要你定制化。选择哪个指标取决于你的业务需求和问题的性质。例如，如果你在处理一个不平衡的分类问题，可能会更关注召回率或F1分数，而不是仅仅关注准确率。

